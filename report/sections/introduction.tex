\section{Introduction}

Automatic and accurate counting of animals in livestock and poultry farms is an important tool for operational monitoring, production planning and animal welfare. Manual counting is laborious, error-prone and not scalable to modern commercial facilities where thousands of birds must be monitored continuously. Computer vision methods that estimate counts from images provide an attractive quick and automated alternative, but pose several technical challenges: dense scenes with heavy occlusion and varying illumination and camera viewpoints.

Classical approaches to visual counting fall into two broad families: object detection (detect-and-count) and density\hyp{}estimation (regress a density map whose integral equals the count). Detection-based methods can fail in heavily occluded scenes or when objects are very small; density\hyp{}estimation methods have proven robust in these settings by learning to predict continuous density maps and using simple integrals to obtain counts \cite{single_image_crowd_counting}. Recent advances in image representations, especially transformer-based backbones, have further improved feature extraction for dense prediction tasks.

This project reimplements the architecture and training strategy proposed in the Sensors 2024 paper "Transforming Poultry Farming: A Pyramid Vision Transformer Approach for Accurate Chicken Counting" \cite{pvt_chicken}. The original work combines a Pyramid Vision Transformer v2 (PVT-v2) backbone with a lightweight pyramid feature aggregation (PFA) module and a Multi-Scale Dilated Convolution (MDC) head to produce high-resolution density maps. Training relies on a curriculum-style combination of losses (counting loss, entropic optimal-transport loss and total-variation regularization) to guide the model from coarse counting to fine-grained spatial alignment.

My reimplementation follows the original design while focusing on reproducibility and practical engineering: we adopt a PVT-v2-B2 backbone (via the \texttt{timm} library \cite{timm}), a PFA aggregation and an MDC head. Dataset coverage was expanded and training uses on-the-fly augmentations (random flips, small rotations, multi-scale crops, photometric jitter, random erasing and occasional copyâ€“paste) to improve robustness.

The remainder of this report is organized as follows. Section 2 reviews related work and positions the PVT-based approach within the counting literature. Section 3 describes the reimplemented model and loss functions in detail. Section 4 presents dataset preparation and experimental protocol. Section 5 reports quantitative results and qualitative examples. Finally, Section 6 discusses future work.
